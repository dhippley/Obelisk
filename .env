# =============================================================================
# Obelisk Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values

# =============================================================================
# Database Configuration
# =============================================================================
DATABASE_URL=ecto://postgres:postgres@localhost/obelisk_dev

# For production, you'll need a full database URL:
# DATABASE_URL=ecto://user:pass@host:port/database
POOL_SIZE=10

# Enable IPv6 support (optional)
# ECTO_IPV6=false

# =============================================================================
# Phoenix Configuration
# =============================================================================
SECRET_KEY_BASE=your-secret-key-base-here
PHX_HOST=localhost
PORT=4000

# Enable Phoenix server in production (set to "true" for releases)
# PHX_SERVER=false

# =============================================================================
# LLM Provider Configuration
# =============================================================================

# OpenAI Configuration (Primary Provider)
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4o-mini
OPENAI_BASE_URL=https://api.openai.com/v1

# Anthropic Configuration (Secondary Provider)
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
ANTHROPIC_BASE_URL=https://api.anthropic.com/v1

# Ollama Configuration (Local Provider)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
OLLAMA_TIMEOUT=60000

# Default LLM Provider (openai, anthropic, ollama)
DEFAULT_LLM_PROVIDER=openai

# =============================================================================
# Embedding Configuration
# =============================================================================
EMBEDDING_PROVIDER=openai
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSIONS=1536

# =============================================================================
# Memory & Retrieval Settings
# =============================================================================
MEMORY_CHUNK_SIZE=1000
MEMORY_CHUNK_OVERLAP=200
DEFAULT_RETRIEVAL_K=5
DEFAULT_SIMILARITY_THRESHOLD=0.7

# =============================================================================
# Performance & Processing Settings
# =============================================================================

# Enable async embedding processing (true/false)
ASYNC_EMBEDDING=true

# Embedding batch processing settings
EMBEDDING_BATCH_SIZE=20
BROADWAY_PROCESSORS=4
BROADWAY_BATCH_SIZE=20
BROADWAY_BATCH_TIMEOUT=5000

# =============================================================================
# Deployment Configuration
# =============================================================================

# DNS cluster query (for distributed deployments)
# DNS_CLUSTER_QUERY=myapp.internal

# SSL Configuration (for production)
# SOME_APP_SSL_KEY_PATH=/path/to/ssl.key
# SOME_APP_SSL_CERT_PATH=/path/to/ssl.crt

# =============================================================================
# Development-Only Settings
# =============================================================================
# These are typically only used in development mode

# Disable async processing for easier debugging (dev only)
# ASYNC_EMBEDDING=false

# Smaller batch sizes for faster feedback (dev only)  
# EMBEDDING_BATCH_SIZE=5

# =============================================================================
# Example Production Values
# =============================================================================
# Here are example values for a production deployment:

# DATABASE_URL=ecto://obelisk_user:secure_password@db.example.com:5432/obelisk_prod
# SECRET_KEY_BASE=$(mix phx.gen.secret)
# PHX_HOST=obelisk.yourdomain.com
# PORT=4000
# PHX_SERVER=true
# DEFAULT_LLM_PROVIDER=openai
# ASYNC_EMBEDDING=true
# EMBEDDING_BATCH_SIZE=50
# BROADWAY_PROCESSORS=8

# =============================================================================
# Quick Setup Guide
# =============================================================================
# 1. Copy this file: cp env.example .env
# 2. Add your OpenAI API key (minimum required)
# 3. Optionally add Anthropic API key for Claude support  
# 4. For local development, start Ollama if you want local LLM support
# 5. Run: source .env && mix phx.server
